{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Python Fundamentals for Seismology — Notebook 8\n## Reading Tables & Metadata with Pandas\n\n*Python Fundamentals for Seismology*\n\nRun cells in order. Edit parameters and re-run to explore.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Learning objectives\n- Understand working directories and file paths\n- Read CSV tables with pandas\n- Inspect DataFrames with head(), shape, dtypes\n- Select and filter rows and columns\n- Compute basic summary statistics\n- Prepare tables for later seismology workflows (catalogs, station metadata)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 0. Setup\nWe will use pandas, NumPy, and matplotlib.\nThese patterns are directly applicable to:\n- event catalogs\n- station metadata tables\n- quality-control summaries\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\npd.set_option(\"display.max_rows\", 10)\npd.set_option(\"display.max_columns\", 10)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Working directories and file paths\nAlways know where your code is running and where files are being read from.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Current working directory\ncwd = os.getcwd()\nprint(\"Current directory:\", cwd)\n\n# List files in the directory\nprint(\"\\nFiles here:\")\nfor name in os.listdir(cwd):\n    print(\"  \", name)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Changing directories (if needed)\nIn scripts, it is often better to use absolute or project-relative paths instead of changing directories.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Creating a small synthetic station metadata table\nWe will create a simple CSV-like table representing station metadata.\nLater, you will replace this with real files (e.g., station lists, catalogs).\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "data = {\n    \"station\": [\"MBGH\", \"MBBY\", \"MBLG\", \"MBFR\", \"MBRY\"],\n    \"latitude\": [16.72, 16.71, 16.69, 16.75, 16.73],\n    \"longitude\": [-62.18, -62.20, -62.22, -62.15, -62.19],\n    \"elevation_m\": [330, 250, 180, 410, 290],\n    \"start_year\": [1996, 1997, 1998, 2000, 1999]\n}\n\ndf = pd.DataFrame(data)\ndf\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Saving to CSV (for practice)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "csv_path = \"station_metadata_example.csv\"\ndf.to_csv(csv_path, index=False)\nprint(\"Wrote:\", csv_path)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Reading a CSV file with pandas\nThe most common entry point for tabular data is `pd.read_csv`.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "df = pd.read_csv(\"station_metadata_example.csv\")\ndf\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Inspecting a DataFrame\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "print(\"shape:\", df.shape)\nprint(\"\\ncolumns:\")\nprint(df.columns)\nprint(\"\\ndtypes:\")\nprint(df.dtypes)\nprint(\"\\nfirst rows:\")\ndf.head()\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Selecting columns and rows\nTwo main access patterns:\n- Column selection: `df['col']`\n- Row/column selection: `.loc[]` and `.iloc[]`\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Single column\nstations = df[\"station\"]\nprint(stations)\n\n# Multiple columns\ncoords = df[[\"latitude\", \"longitude\"]]\ncoords\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Row selection by index\nprint(df.iloc[0])          # first row\nprint(df.iloc[1:4])       # rows 1–3\n\n# Row selection by condition\nhigh_stations = df[df[\"elevation_m\"] >= 300]\nhigh_stations\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Sorting and filtering\nSorting and filtering are extremely common in catalog and metadata workflows.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Sort by elevation\ndf_sorted = df.sort_values(\"elevation_m\", ascending=False)\ndf_sorted\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Filter by start year\nold_stations = df[df[\"start_year\"] <= 1998]\nold_stations\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. Basic summary statistics\nPandas provides many built-in summary operations.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Summary for numeric columns\ndf.describe()\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Column-wise statistics\nprint(\"Mean elevation:\", df[\"elevation_m\"].mean())\nprint(\"Max elevation :\", df[\"elevation_m\"].max())\nprint(\"Min elevation :\", df[\"elevation_m\"].min())\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7. Adding derived columns\nIt is common to compute new columns from existing ones.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Example: approximate distance from a reference point\nlat0, lon0 = 16.72, -62.18\n\n# crude distance in km (flat Earth approximation for teaching)\ndf[\"dist_km\"] = 111.0 * np.sqrt((df[\"latitude\"] - lat0)**2 + (df[\"longitude\"] - lon0)**2)\n\ndf\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8. Grouping and aggregation\nGrouping is essential for summarizing by station, day, phase type, etc.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Create a tiny synthetic event table\nevents = pd.DataFrame({\n    \"station\": [\"MBGH\", \"MBGH\", \"MBBY\", \"MBLG\", \"MBGH\", \"MBBY\"],\n    \"magnitude\": [2.1, 3.4, 1.8, 2.9, 4.2, 3.0]\n})\n\nevents\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Mean magnitude by station\nevents.groupby(\"station\")[\"magnitude\"].mean()\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Joining tables (metadata + events)\nVery common pattern: join catalogs with station metadata.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "merged = pd.merge(events, df, on=\"station\", how=\"left\")\nmerged\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 9. Plotting simple summaries from tables\nQuick diagnostic plots are invaluable for QC.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "plt.figure()\nplt.bar(df[\"station\"], df[\"elevation_m\"])\nplt.ylabel(\"Elevation (m)\")\nplt.title(\"Station elevations\")\nplt.show()\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "plt.figure()\nplt.hist(events[\"magnitude\"], bins=5)\nplt.xlabel(\"Magnitude\")\nplt.ylabel(\"Count\")\nplt.title(\"Event magnitude distribution\")\nplt.show()\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 10. Common pitfalls and good habits\n- Always print `df.shape` after reading a file\n- Inspect `df.head()` before trusting the data\n- Be explicit about column names\n- Avoid silent type conversion errors\n- Keep raw tables and derived tables separate\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Exercises\n1. Load the CSV and select only stations above 250 m elevation.\n2. Compute the mean elevation of those stations.\n3. Add a column `is_high` that is True for elevation >= 300 m.\n4. Group the `events` table by station and compute:\n   - count of events\n   - mean magnitude\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# 1) Filter stations above 250 m\nhigh = None\n\n# 2) Mean elevation of high stations\nmean_high = None\n\n# 3) Add is_high column\ndf2 = df.copy()\n# TODO\n\n# 4) Group and summarize events\nsummary = None\n\nprint(\"high:\\n\", high)\nprint(\"mean_high:\", mean_high)\nprint(\"df2:\\n\", df2)\nprint(\"summary:\\n\", summary)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Solutions (peek after trying)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "high = df[df[\"elevation_m\"] > 250]\nmean_high = high[\"elevation_m\"].mean()\n\ndf2 = df.copy()\ndf2[\"is_high\"] = df2[\"elevation_m\"] >= 300\n\nsummary = events.groupby(\"station\")[\"magnitude\"].agg([\"count\", \"mean\"])\n\nprint(\"high:\\n\", high)\nprint(\"mean_high:\", mean_high)\nprint(\"df2:\\n\", df2)\nprint(\"summary:\\n\", summary)\n",
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}