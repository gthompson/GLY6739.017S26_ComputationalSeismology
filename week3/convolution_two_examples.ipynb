{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Convolution: what it is, and two places it naturally appears\n*(Signals & Systems + Probability, with worked Python examples)*\n\nThis notebook builds intuition for **convolution** and shows two standard places it appears:\n\n1. **Linear time-invariant (LTI) systems**: output = input convolved with impulse response  \n2. **Probability**: the PDF of a sum of independent random variables is a convolution of PDFs\n\nWe’ll do both conceptually and computationally, with small examples you can edit.\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 0. Setup\n\nWe'll use only NumPy + Matplotlib.  \n(If you're in a signals course, you can later swap in `scipy.signal` utilities, but it's not required here.)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Pretty printing\nnp.set_printoptions(precision=4, suppress=True)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. The definition\n\n### Continuous-time\nThe convolution of two functions \\(f\\) and \\(g\\) is\n\n\\[\n(f * g)(t) = \\int_{-\\infty}^{\\infty} f(\\tau)\\, g(t-\\tau)\\, d\\tau\n\\]\n\n### Discrete-time\nFor sequences \\(x[n]\\) and \\(h[n]\\),\n\n\\[\n(x * h)[n] = \\sum_{k=-\\infty}^{\\infty} x[k] \\, h[n-k]\n\\]\n\n**Interpretation:** a *weighted sum of shifted copies* of one signal, where the weights come from the other signal.\n\n> In LTI systems, \\(h\\) is the **impulse response** and \\(y = x*h\\).\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. A \"sliding dot-product\" viewpoint (discrete)\n\nIn discrete time, think of convolution as:\n1. pick an output index \\(n\\)\n2. line up **all** pairs \\(x[k]\\) with \\(h[n-k]\\)\n3. multiply pairwise and sum\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def conv_sum(x, h):\n    \"\"\"Direct convolution using the definition (O(N^2)).\"\"\"\n    x = np.asarray(x)\n    h = np.asarray(h)\n    y = np.zeros(len(x) + len(h) - 1, dtype=float)\n    for n in range(len(y)):\n        s = 0.0\n        for k in range(len(x)):\n            j = n - k\n            if 0 <= j < len(h):\n                s += x[k] * h[j]\n        y[n] = s\n    return y\n\n# Small example\nx = np.array([1, 2, 1])\nh = np.array([1, -1, 0.5])\n\ny_manual = conv_sum(x, h)\ny_np = np.convolve(x, h)\n\nprint(\"x =\", x)\nprint(\"h =\", h)\nprint(\"manual conv =\", y_manual)\nprint(\"numpy conv  =\", y_np)\nprint(\"max abs diff =\", np.max(np.abs(y_manual - y_np)))\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Example 1 (Signals): an LTI system as a smoothing filter\n\nA classic LTI system is a **moving average** (a simple low-pass / smoothing filter):\n\n\\[\nh[n] = \\frac{1}{M}\\, \\underbrace{[1,1,\\dots,1]}_{M\\ \\text{samples}}\n\\]\n\nThen \\(y = x * h\\) is a local average of the last \\(M\\) samples (up to alignment conventions).\n\nWe'll create a noisy signal and smooth it with convolution.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Create a synthetic signal: sinusoid + noise + an impulse (to show the filter shape)\nfs = 100  # Hz\nt = np.arange(0, 5, 1/fs)\nrng = np.random.default_rng(7)\n\nx = np.sin(2*np.pi*1.2*t) + 0.35*rng.standard_normal(len(t))\nx[int(2.2*fs)] += 3.0  # a spike\n\n# Moving average impulse response\nM = 25\nh = np.ones(M)/M\n\n# Convolve (mode='same' keeps length aligned to x for plotting convenience)\ny = np.convolve(x, h, mode='same')\n\nplt.figure()\nplt.plot(t, x, label='x[n] (noisy input)')\nplt.plot(t, y, label='y[n] = x*h (smoothed)')\nplt.xlabel('Time (s)')\nplt.ylabel('Amplitude')\nplt.title('Moving average as an LTI system (convolution)')\nplt.legend()\nplt.show()\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 3.1 Impulse response intuition\n\nIf you input an impulse, the output of an LTI system is its **impulse response**.\n\nLet's approximate an impulse (a single 1 surrounded by zeros) and see that convolving it with \\(h\\) gives back \\(h\\).\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "N = 200\ndelta = np.zeros(N)\ndelta[80] = 1.0  # discrete-time impulse at n=80\n\nout = np.convolve(delta, h, mode='same')\n\nplt.figure()\nplt.stem(np.arange(N), delta, basefmt=\" \", label='delta[n]')\nplt.stem(np.arange(N), out, basefmt=\" \", label='delta*h')\nplt.xlim(40, 140)\nplt.xlabel('n (samples)')\nplt.title('Impulse response via convolution')\nplt.legend()\nplt.show()\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 3.2 Deconvolving your intuition: \"shape modifies shape\"\n\nConvolution often feels like: *one shape gets “smeared” by another*.\n\n- A narrow \\(h\\) (small \\(M\\)) smears a little → mild smoothing\n- A wide \\(h\\) (large \\(M\\)) smears more → heavy smoothing but more delay/blur\n\nTry changing `M` above.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Example 2 (Probability): adding independent random variables\n\nIf \\(X\\) and \\(Y\\) are independent random variables with PDFs \\(f_X\\) and \\(f_Y\\), then the PDF of \\(Z=X+Y\\) is\n\n\\[\nf_Z(z) = (f_X * f_Y)(z)\n\\]\n\nWe'll show the classic result: **Uniform + Uniform = Triangular**.\n\nWe'll do it two ways:\n- numerically convolving sampled PDFs\n- Monte Carlo simulation (histogram of sums)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Define a grid\ndz = 0.001\nz = np.arange(-2, 2+dz, dz)\n\ndef uniform_pdf(z, a=-0.5, b=0.5):\n    out = np.zeros_like(z, dtype=float)\n    out[(z >= a) & (z <= b)] = 1.0/(b-a)\n    return out\n\nf = uniform_pdf(z, -0.5, 0.5)  # X ~ U(-0.5, 0.5)\ng = uniform_pdf(z, -0.5, 0.5)  # Y ~ U(-0.5, 0.5)\n\n# Discrete approximation to continuous convolution:\n# integral becomes a sum, so multiply by dz.\nfz = np.convolve(f, g, mode='same') * dz\n\nplt.figure()\nplt.plot(z, f, label='f_X (uniform)')\nplt.plot(z, fz, label='f_Z (via convolution)')\nplt.xlim(-1.5, 1.5)\nplt.xlabel('value')\nplt.ylabel('density')\nplt.title('PDF of Z = X + Y (convolution)')\nplt.legend()\nplt.show()\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Monte Carlo check\nrng = np.random.default_rng(0)\nN = 200000\nX = rng.uniform(-0.5, 0.5, size=N)\nY = rng.uniform(-0.5, 0.5, size=N)\nZ = X + Y\n\nplt.figure()\nplt.hist(Z, bins=120, density=True, alpha=0.5, label='Monte Carlo histogram of X+Y')\nplt.plot(z, fz, label='Convolution result')\nplt.xlim(-1.5, 1.5)\nplt.xlabel('value')\nplt.ylabel('density')\nplt.title('Monte Carlo agrees with convolution')\nplt.legend()\nplt.show()\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Optional: discrete-time convolution as polynomial multiplication\n\nIf you treat two finite sequences as polynomial coefficients, convolution corresponds to multiplying polynomials.\nThat’s one reason convolution is so common in DSP, control, and probability.\n\nTry this with small vectors and compare:\n- `np.convolve(x, h)`\n- `np.polynomial.polynomial.polymul(x, h)`\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "x = np.array([1, 2, 1])\nh = np.array([1, -1, 0.5])\n\nprint('np.convolve:', np.convolve(x, h))\nprint('polymul   :', np.polynomial.polynomial.polymul(x, h))\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. Practice problems\n\n1. **Smoothing and lag**  \n   Use a moving average of length `M=5`, `M=25`, `M=101`.  \n   What changes in the output? Where do you see “lag” or “blur”?\n\n2. **Edge effects**  \n   Try `mode='full'`, `'same'`, and `'valid'` in `np.convolve`.  \n   Explain the output lengths.\n\n3. **A simple differentiator**  \n   Use `h = [1, -1]` and convolve with a smooth sinusoid.  \n   What does the output resemble?\n\n4. **Probability**  \n   Replace uniform distributions with:\n   - Gaussian + Gaussian (should remain Gaussian)\n   - Uniform + Gaussian (becomes a smoothed uniform)  \n   Use Monte Carlo to verify.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## References\n\n- Convolution definitions and properties: Wikipedia, *Convolution*.  \n- Convolution of probability distributions and sums of independent RVs: Wikipedia, *Convolution of probability distributions*.  \n- Discrete-time convolution as LTI system output (intro text): Signals & Systems (Baraniuk et al., LibreTexts).  \n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}